<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed to the Apache Software Foundation (ASF) under one or more
  contributor license agreements.  See the NOTICE file distributed with
  this work for additional information regarding copyright ownership.
  The ASF licenses this file to You under the Apache License, Version 2.0
  (the "License"); you may not use this file except in compliance with
  the License.  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!DOCTYPE document PUBLIC "-//APACHE//DTD Documentation V2.0//EN" "http://forrest.apache.org/dtd/document-v20.dtd">
<document>
  <header>
    <title>Pig Quick Start</title>
  </header>
  <body>
  
    <section id="req">
      <title>Requirements</title>
      
      <p><strong>Unix</strong> and <strong>Windows</strong> users need the following:</p>
		<ol>
		  <li> <strong>Hadoop 18</strong>: <a href="http://hadoop.apache.org/core/">http://hadoop.apache.org/core/</a></li>
		  <li> <strong>Java 1.6</strong>, preferably from Sun: <a href="http://java.sun.com/javase/downloads/index.jsp">http://java.sun.com/javase/downloads/index.jsp</a>. Set JAVA_HOME to the root of your Java installation.</li>
		  <li> <strong>Ant</strong> for builds: <a href="http://ant.apache.org/">http://ant.apache.org/</a>.</li>
		  <li> <strong>JUnit</strong> for unit tests: <a href="http://junit.sourceforge.net/">http://junit.sourceforge.net/</a>.</li>
		</ol>
	<p><strong>Windows</strong> users need to install Cygwin and the Perl package: <a href="http://www.cygwin.com/"> http://www.cygwin.com/</a>.</p>
   </section>
        
    <section>
      <title>Building Pig </title>
     <ol>
	  <li> Check out the Pig code from SVN: <em>svn co http://svn.apache.org/repos/asf/hadoop/pig/trunk</em>. </li>
	  <li> Build the code from the top directory: <em>ant</em>. If the build is successful, you should see the <em>pig.jar</em> created in that directory. </li>	
	  <li> Validate your <em>pig.jar</em> by running a unit test: <em>ant test</em></li>
     </ol>
    </section>

<section>
	<title>Running Pig</title>

<section>
	<title>Overview</title>
	<p>This section discusses the Pig run modes and the different ways you can run Pig using these modes. </p>
	
<section>
<title>Run Modes</title>

<p>Pig has two run modes or exectypes, local and hadoop (mapreduce).  </p>
<ul>
<li><p> <strong>Local Mode</strong>: To run Pig in local mode, you need access to a single machine.  </p>
</li>
<li><p> <strong>Hadoop (mapreduce) Mode</strong>: To run Pig in hadoop (mapreduce) mode, you need access to a Hadoop cluster and HDFS installation. </p>
</li>
</ul>
<p>To get a listing of all Pig commands, including the run modes, use:  
</p>

<source>
$ pig –help
</source>
</section>

<section>
<title>Run Ways</title>

<p>You can run Pig three ways – using either local mode or hadoop (mapreduce) mode: </p>
<ul>
<li><p> <strong>Grunt Shell</strong>: Enter Pig commands manually using Pig’s interactive shell, Grunt.  </p>
</li>
<li><p> <strong>Script File</strong>: Place Pig commands in a script file and run the script. </p>
</li>
<li><p> <strong>Embedded Program</strong>: Embed Pig commands in a host language and run the program. </p>
</li>
</ul>
<p>Note: Also see the Pig Latin exec and run commands. </p>
</section>

<section>
<title>Sample Code</title>

<p>The examples in this section are based on these Pig Latin statements, which extract all user IDs from the /etc/passwd file.  </p>

 <p>To set environment variables, use the right command for your shell:  </p>
	<ul>
		<li><p> setenv PIGDIR /pig  (tcsh, csh)  </p>
		</li>
		<li><p> export PIGDIR=/pig (bash, sh, ksh) </p>
		</li>
	</ul>
<p>The examples in the Running Pig section use export.</p>
	
<section>
<title>id.pig</title>
<source>
A = load 'passwd' using PigStorage(':'); 
B = foreach A generate $0 as id;
dump B; 
store B into ‘id.out’;
</source>
</section>

<section>
<title>idlocal.java</title>
<source>
import java.io.IOException;
import org.apache.pig.PigServer;
public class idlocal{ 
public static void main(String[] args) {
try {
    PigServer pigServer = new PigServer("local");
    runIdQuery(pigServer, "passwd");
    }
    catch(Exception e) {
    }
 }
public static void runIdQuery(PigServer pigServer, String inputFile) throws IOException {
    pigServer.registerQuery("A = load '" + inputFile + "' using PigStorage(':');");
    pigServer.registerQuery("B = foreach A generate $0 as id;");
    pigServer.store("B", "id.out");
 }
}
</source>
</section>

<section>
<title>idhadoop.java</title>
<source>
import java.io.IOException;
import org.apache.pig.PigServer;
public class idhadoop {
   public static void main(String[] args) {
   try {
     PigServer pigServer = new PigServer("mapreduce");
     runIdQuery(pigServer, "passwd");
   }
   catch(Exception e) {
   }
}
public static void runIdQuery(PigServer pigServer, String inputFile) throws IOException {
   pigServer.registerQuery("A = load '" + inputFile + "' using PigStorage(':');")
   pigServer.registerQuery("B = foreach A generate $0 as id;");
   pigServer.store("B", "idout");
   }
}
</source>

</section>
</section>
</section>

<section>
<title>Local Mode</title>

<p>This section shows you how to run Pig in local mode, using the Grunt shell, a Pig script, and an embedded program.  </p>
<p>To run Pig in local mode, you only need access to a single machine. To make things simple, copy these files to your current working directory (you may want to create a temp directory and move to it): </p>
<ul>
<li><p> The /etc/passwd file </p>
</li>
<li><p> The pig.jar file, created when you build Pig. </p>
</li>
<li><p> The sample code files (id.pig and idlocal.java) located on this page </p>
</li>
</ul>

<section>
<title> Grunt Shell</title>

<p>To run Pig’s Grunt shell in local mode, follow these instructions. </p>
<p>First, point $PIG_CLASSPATH to the pig.jar file (in your current working directory): 
</p>
<source>
$ export PIG_CLASSPATH=./pig.jar
</source>
<p> </p>
<p>From your current working directory, run: 
</p>
<source>
$ pig -x local
</source>
<p>The Grunt shell is invoked and you can enter commands at the prompt. 
</p>
<source>
grunt&gt; A = load 'passwd' using PigStorage(':'); 
grunt&gt; B = foreach A generate $0 as id; 
grunt&gt; dump B; 
</source>

</section>

<section>
<title>Script File</title>

<p>To run a Pig script file in local mode, follow these instructions (which are the same as the Grunt Shell instructions above – you just include the script file). </p>
<p>First, point $PIG_CLASSPATH to the pig.jar file (in your current working directory): 
</p>
<source>
$ export PIG_CLASSPATH=./pig.jar
</source>
<p>From your current working directory, run: </p>

<source>
$ pig -x local id.pig
</source>
<p>The Pig Latin statements are executed and the results are displayed  to your terminal screen. </p>
</section>

<section>
<title> Embedded Program</title>

<p>To compile and run an embedded Java/Pig program in local mode, follow these instructions.  </p>
<p>From your current working directory, compile the program: 
</p>
<source>
$ javac -cp pig.jar idlocal.java
</source>
<p>Note: idlocal.class is written to your current working directory. Include “.” in the class path when you run the program. </p>
<p>From your current working directory, run the program: 
</p>
<source>
Unix:   $ java -cp pig.jar:. idlocal
Cygwin: $ java –cp ‘.;pig.jar’ idlocal
</source>
<p>To view the results, check the output file, id.out. </p>
</section>
</section>

<section>
<title>Hadoop Mode</title>

<p>This section shows you how to run Pig in hadoop (mapreduce) mode, using the Grunt shell, a Pig script, and an embedded program. </p>
<p>To run Pig in hadoop (mapreduce) mode, you need access to a Hadoop cluster. You also need to copy these files to your home or current working directory. </p>
<ul>
<li><p> The /etc/passwd file </p>
</li>
<li><p> The pig.jar file, created when you build Pig. </p>
</li>
<li><p> The sample code files (id.pig and idhadoop.java) located on this page </p>
</li>
</ul>

<section>
<title>Grunt Shell</title>

<p>To run Pig’s Grunt shell in hadoop (mapreduce) mode, follow these instructions. When you begin the session, Pig will allocate a 15-node cluster. When you quit the session, Pig will deallocate the nodes. </p>
<p>From your current working directory, run: 
</p>
<source>
$ pig
 or
$ pig -x mapreduce
</source>
<p>The Grunt shell is invoked and you can enter commands at the prompt. 
</p>
<source>
grunt&gt; A = load 'passwd' using PigStorage(':'); 
grunt&gt; B = foreach A generate $0 as id; 
grunt&gt; dump B; 
</source>

</section>

<section>
<title>Script File</title>

<p>To run Pig script files in hadoop (mapreduce) mode, follow these instructions (which are the same as the Grunt Shell instructions above – you just include the script file). Again, Pig will automatically allocate and deallocate a 15-node cluster. </p>
<p>From your current working directory, run: 
</p>
<source>
$ pig id.pig
or
$ pig -x mapreduce id.pig
</source>
<p>The Pig Latin statements are executed and the results are displayed to your terminal screen. </p>
</section>

<section>
<title>Embedded Program</title>

<p>To compile and run an embedded Java/Pig program in hadoop (mapreduce) mode, follow these instructions.  </p>
<p>First, point $HADOOPDIR to the directory that contains the hadoop-site.xml file. Example: 
</p>
<source>
$ export HADOOPDIR=/yourHADOOPsite/conf 
</source>
<p>From your current working directory, compile the program: 
</p>
<source>
$ javac -cp pig.jar idhadoop.java
</source>
<p>Note: idhadoop.class is written to your current working directory. Include “.” in the class path when you run the program. </p>
<p>From your current working directory, run the program: 
</p>
<source>
Unix:   $ java -cp pig.jar:.:$HADOOPDIR idhadoop
Cygwin: $ java –cp ‘.;pig.jar;$HADOOPDIR’ idhadoop
</source>
<p>To view the results, check the idout directory on your Hadoop system. </p>

</section>
</section>
</section>
</body>
</document>
